# -*- coding: utf-8 -*-
"""cars_resnet50V2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JVFMHtfsqOfWufAgzK1TSSFfHY0fVHYc
"""

# -*- coding: utf-8 -*-


from __future__ import print_function
import keras
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, Input
from keras.layers import Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization as BN
from keras.layers import GaussianNoise as GN
from keras.optimizers import SGD, Adam, RMSprop
from keras.models import Model
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os

from keras.callbacks import LearningRateScheduler as LRS
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import decode_predictions
from keras.callbacks import ModelCheckpoint

batch_size = 16
num_classes = 20
epochs_freeze = 40
epochs_defrost = 60

# Probar otros parametros
datagen = ImageDataGenerator(
  width_shift_range=0.28,
  height_shift_range=0.28,
  rotation_range=19,
  zoom_range=[1.0,1.2],
  horizontal_flip=True)

#### LOAD AND TRANSFORM

# ## Download: ONLY ONCE!
# os.system('wget https://www.dropbox.com/s/sakfqp6o8pbgasm/data.tgz')
# os.system('tar xvzf data.tgz')
# #####

# Load 
x_train = np.load('drive/MyDrive/VPC/cars/x_train.npy')
x_test = np.load('drive/MyDrive/VPC/cars/x_test.npy')

y_train = np.load('drive/MyDrive/VPC/cars/y_train.npy')
y_test = np.load('drive/MyDrive/VPC/cars/y_test.npy')

# Stats
print(x_train.shape)
print(y_train.shape)

print(x_test.shape)
print(y_test.shape)

## View some images
plt.imshow(x_train[2,:,:,: ] )
plt.show()


## Transforms
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

y_train = y_train.astype('float32')
y_test = y_test.astype('float32')


x_train /= 255
x_test /= 255


## Labels
y_train=y_train-1

y_test=y_test-1

y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)
############################################################
###########################################################
print(x_train.shape)

#Cargamos el modelo vgg16
model1 = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=tf.keras.layers.Input(shape=(250, 250, 3)))
for layer in model1.layers:
  layer.trainable  = False
model1.summary()

#############################
###      BILINEAR        ####
#############################

def outer_product(x):
  phi_I = tf.einsum('ijkm,ijkn->imn',x[0],x[1])		# Einstein Notation  [batch,31,31,depth] x [batch,31,31,depth] -> [batch,depth,depth]
  phi_I = tf.reshape(phi_I,[-1,2048*2048])	        # Reshape from [batch_size,depth,depth] to [batch_size, depth*depth]
  phi_I = tf.divide(phi_I,8*8)								  # Divide by feature map size [sizexsize]

  y_ssqrt = tf.multiply(tf.sign(phi_I),tf.sqrt(tf.abs(phi_I)+1e-12))		# Take signed square root of phi_I
  z_l2 = tf.nn.l2_normalize(y_ssqrt)								              # Apply l2 normalization
  return z_l2



conv=model1.get_layer('conv5_block3_out') 
d1=Dropout(0.5)(conv.output)   ## Why??
d2=Dropout(0.5)(conv.output)   ## Why??

x = tf.keras.layers.Lambda(outer_product, name='outer_product')([d1,d2])

predictions=tf.keras.layers.Dense(num_classes, activation='softmax', name='predictions')(x)

model = tf.keras.models.Model(inputs=model1.input, outputs=predictions)

# Probar 0.01
opt = Adam(lr=0.01, decay=1e-6)
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])
    
  
model.summary()
filepath="drive/MyDrive/VPC/gender/weights_freeze.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
## TRAINING with DA and LRA
history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),
                            steps_per_epoch=len(x_train) / batch_size, 
                            epochs=epochs_freeze,
                            validation_data=(x_test, y_test),
                            callbacks=callbacks_list,
                            verbose=1)

model.load_weights("drive/MyDrive/VPC/gender/weights_defrost.hdf5")

for layer in model.layers:
  layer.trainable  = True
#opt = SGD(lr=0.0001, decay=1e-6)
opt = Adam(lr=0.000001, decay=1e-6)
# model.compile(loss='categorical_crossentropy',
#               optimizer=opt,
#               metrics=['accuracy'])
# history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),
#                             steps_per_epoch=len(x_train) / batch_size, 
#                             epochs=epochs,
#                             validation_data=(x_test, y_test),
                            
#                             verbose=1)


#opt = SGD(lr=0.0001, decay=1e-6)

model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

filepath_defrost="drive/MyDrive/VPC/gender/weights_defrost_120.hdf5"
checkpoint_defrost = ModelCheckpoint(filepath_defrost, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list_defrost = [checkpoint_defrost]
history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),
                            steps_per_epoch=len(x_train) / batch_size, 
                            epochs=epochs_defrost,
                            validation_data=(x_test, y_test),
                            callbacks=callbacks_list_defrost,
                            verbose=1)