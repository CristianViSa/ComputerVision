# -*- coding: utf-8 -*-
"""gender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tKTar17-5NAc9cKmjTIOs1Jd8Lt82ZPA
"""

import numpy as np
import matplotlib.pyplot as plt
from __future__ import print_function
import keras
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization as BN
from keras.layers import GaussianNoise as GN
from keras.optimizers import SGD
import tensorflow 
from keras.callbacks import LearningRateScheduler as LRS
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint

# Load 
x_train = np.load("drive/MyDrive/VPC/gender/x_train.npy")
x_train = x_train[:,18:82,18:82,:]
x_test = np.load("drive/MyDrive/VPC/gender/x_test.npy")
x_test = x_test[:,18:82,18:82,:]

y_train = np.load("drive/MyDrive/VPC/gender/y_train.npy")
y_test = np.load("drive/MyDrive/VPC/gender/y_test.npy")


# Stats
print(x_train.shape)
print(y_train.shape)
print(sum(y_train == 1))
print(sum(y_train == 0))
print("{:.4f}".format(sum(y_train == 1)/y_train.shape[0]))
print(x_test.shape)
print(y_test.shape)
print(sum(y_test == 1))
print(sum(y_test == 0))
print("{:.4f}".format(sum(y_test == 1)/y_test.shape[0]))


## View some images
plt.imshow(x_train[1,:,:,: ] )
plt.show()

## Transforms
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

y_train = y_train.astype('float32')
y_test = y_test.astype('float32')


x_train /= 255
x_test /= 255

print(x_train.shape)
print(x_test.shape)


num_classes = 2

y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)
y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)

datagen = ImageDataGenerator(
    width_shift_range=0.18,
    height_shift_range=0.18,
    zoom_range=0.18,
    rotation_range = 10,
    horizontal_flip=True)

batch_size = 128
num_classes = 2
epochs = 150




## DEF NN TOPOLOGY  
model = Sequential()

model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))

model.add(BN())
model.add(Activation('relu'))


model.add(Conv2D(32, (3, 3), padding='same'))
model.add(BN())
model.add(Activation('relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))


model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))

model.add(BN())
model.add(Activation('relu'))


model.add(Conv2D(32, (3, 3), padding='same'))
model.add(BN())
model.add(Activation('relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))


model.add(Conv2D(64, (3, 3), padding='same'))

model.add(BN())
model.add(Activation('relu'))


model.add(Conv2D(64, (3, 3), padding='same'))
model.add(BN())
model.add(Activation('relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))



model.add(Flatten())

model.add(Dense(num_classes))
model.add(Activation('softmax'))


model.summary()

dot_img_file = 'model_1.png'

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)


## OPTIM AND COMPILE
opt = keras.optimizers.Adam(learning_rate=0.01)

model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

# DEFINE A LEARNING RATE SCHEDULER
def scheduler(epoch):
    if epoch < 25:
        return 0.1
    elif epoch < 50:
        return 0.01
    elif epoch < 75:
        return 0.001
    elif epoch < 100:
        return 0.0001
    else:
        return 0.00001
    
set_lr = LRS(scheduler)
filepath="drive/MyDrive/VPC/gender/weights_97.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
## TRAINING with DA and LRA
history=model.fit_generator(generator = datagen.flow(x_train,y_train,batch_size=batch_size),
                            steps_per_epoch=len(x_train) / batch_size, 
                            epochs=epochs,
                            validation_data=(x_test, y_test),
                            callbacks=callbacks_list,
                            verbose=1)

## TEST
scores = model.evaluate(x_test, y_test, verbose=1) 
print('Test loss:', scores[0])
print('Test accuracy:', scores[1])



plt.title("Loss")
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='val')
plt.legend()
plt.show()

plt.title("Accuracy")
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='val')
plt.legend()
plt.show()

